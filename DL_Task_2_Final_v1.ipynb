{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Task_2_Final_v1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girisiman/Deep_Learning_Tasks/blob/master/DL_Task_2_Final_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN6ej1gCGfl6",
        "colab_type": "code",
        "outputId": "6c63fda8-3195-42a3-9b45-1c670c65b102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras.datasets.mnist as fashion_mnist\n",
        "import keras\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras import regularizers\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Layer\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import  KerasClassifier\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pceZML04Jso7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Result1 = {'mlp_accu': [], 'rf_accu':[], 'cnn_acu':[]}\n",
        "Result2 = {'ae_mle_acc':[],'ae_rf_accu':[]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXsyjpJqGrJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to build basic mlp:\n",
        "def mlp_model(layers,activation, optimizer,drop_out, num_classes=10):\n",
        "  ''' Build a simple mlp model for multi-class classification;  \n",
        "      Arguments:all the hyperparametes (layers,act,opt, drop_out) to buld in a mlp provided by dictionary of parameters used during hyperparameter\n",
        "      optimization\n",
        "           '''\n",
        "  model = Sequential()\n",
        "  for i in range(len(layers)):\n",
        "    if i == 0:\n",
        "        model.add(Dense(layers[i], activation=activation, input_shape=(784,)))\n",
        "        model.add(Dropout(drop_out))\n",
        "    else:\n",
        "      model.add(Dense(layers[i], activation=activation))\n",
        "      model.add(Dropout(drop_out))\n",
        "  model.add(Dense(num_classes, activation=activation))\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe0wCwb4PPcZ",
        "colab_type": "code",
        "outputId": "9029fdc8-e696-45eb-bacc-aba26ea43f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras import backend\n",
        "print(backend.image_data_format())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "channels_last\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeThOQ1WGzuJ",
        "colab_type": "code",
        "outputId": "58e6e73c-6b12-4687-baf4-389b67db6076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape, 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test,10)\n",
        "y_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "(60000, 784) train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfJdwtHZG8Xo",
        "colab_type": "code",
        "outputId": "c6d369b9-83f8-4338-9587-f84a86606ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2499
        }
      },
      "source": [
        "model = KerasClassifier(build_fn=mlp_model, epochs=10, batch_size=128, verbose=0)\n",
        "parameter = {'layers':[[512,512],[512,512,512]],'activation': [ 'relu',],\n",
        "             'optimizer': [ 'Adam' ],\n",
        "             'drop_out': [ 0.5]}\n",
        "classifier = GridSearchCV(estimator=model, param_grid=parameter)\n",
        "search_result = classifier.fit(x_train, y_train)\n",
        "#print(\"Best Accuracy: %f using %s\" % (search_result.best_score_, search_result.best_params_))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 932,362\n",
            "Trainable params: 932,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 932,362\n",
            "Trainable params: 932,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 932,362\n",
            "Trainable params: 932,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_22 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 932,362\n",
            "Trainable params: 932,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyyEkvflI0uV",
        "colab_type": "code",
        "outputId": "fb1690a4-0441-4186-824b-b0f458b91cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "Result1 = {'mlp_accu': [], 'rf_accu':[], 'cnn_acu':[]}\n",
        "best_estimator = classifier.best_estimator_\n",
        "best_model = classifier.best_estimator_.model\n",
        "metric_names_mlp = best_model.metrics_names\n",
        "metric_values_mlp = best_model.evaluate(x_test, y_test)\n",
        "#Result1.update(mlp_accu = metric_values_mlp[1])\n",
        "for metric, value in zip(metric_names_mlp, metric_values_mlp):\n",
        "    print(metric, ': ', value)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 66us/step\n",
            "loss :  0.3236925237879157\n",
            "acc :  0.9371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2RWi5fO2i8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Result1.update(mlp_accu = metric_values_mlp[1]*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8hYUJeGJtz0",
        "colab_type": "code",
        "outputId": "4cca6bd9-6b8d-427c-dfb2-89108a43cec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model_rfc = RandomForestClassifier(n_estimators=64, n_jobs=-1)\n",
        "model_rfc.fit(x_train, y_train)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=64, n_jobs=-1,\n",
              "                       oob_score=False, random_state=None, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5PopGvTKfnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfc_accuracy = model_rfc.score(x_test,y_test)*100\n",
        "rfc_accuracy\n",
        "Result1.update(rf_accu=rfc_accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8mAfgTM6U_B",
        "colab_type": "text"
      },
      "source": [
        "##CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYzYH52SOntn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "34a24626-e2ac-4fee-8d1a-cb37f4b299ee"
      },
      "source": [
        "#preparing data for CNN:\n",
        "from keras import backend as K\n",
        "image_rows, image_cols = 28, 28\n",
        "num_classes = 10\n",
        "(x_train_cnn, y_train_cnn), (x_test_cnn, y_test_cnn) = fashion_mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train_cnn = x_train_cnn.reshape(x_train_cnn.shape[0], 1, image_rows, image_cols)\n",
        "    x_test_cnn = x_test_cnn.reshape(x_test_cnn.shape[0], 1, image_rows, image_cols)\n",
        "    input_shape = (1, image_rows, image_cols)\n",
        "else:\n",
        "    x_train_cnn = x_train_cnn.reshape(x_train_cnn.shape[0], image_rows, image_cols, 1)\n",
        "    x_test_cnn = x_test_cnn.reshape(x_test_cnn.shape[0], image_rows, image_cols, 1)\n",
        "    input_shape = (image_rows, image_cols, 1)\n",
        "\n",
        "x_train_cnn = x_train_cnn.astype('float32')\n",
        "x_test_cnn = x_test_cnn.astype('float32')\n",
        "x_train_cnn /= 255\n",
        "x_test_cnn /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train_cnn = keras.utils.to_categorical(y_train_cnn, num_classes)\n",
        "y_test_cnn = keras.utils.to_categorical(y_test_cnn, num_classes)\n",
        "print(x_train_cnn.shape)\n",
        "print(y_train_cnn.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTGa-5wRMuwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "\n",
        "def cnn_model(dense_layer_sizes, filters, kernel_size, pool_size):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters, kernel_size,\n",
        "                     padding='valid',\n",
        "                     input_shape=input_shape))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(filters, kernel_size))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=pool_size))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  for layer_size in dense_layer_sizes:\n",
        "        model.add(Dense(layer_size))\n",
        "        model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        "  opt = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-gLc06GOWrk",
        "colab_type": "code",
        "outputId": "067afdd8-916f-44dd-8b67-da2616ac7cea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3621
        }
      },
      "source": [
        "param = {'dense_layer_sizes': [[512],[512,512]],  'filters':[8], 'kernel_size': [3], 'pool_size':[2]}\n",
        "my_classifier = KerasClassifier(cnn_model,epochs = 15, batch_size=126)\n",
        "validator = GridSearchCV(my_classifier,\n",
        "                         param_grid=param,\n",
        "                         scoring ='neg_log_loss',\n",
        "                         n_jobs=1)\n",
        "search_result = validator.fit(x_train_cnn, y_train_cnn)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 0.3268 - acc: 0.8982\n",
            "Epoch 2/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.1206 - acc: 0.9624\n",
            "Epoch 3/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0926 - acc: 0.9713\n",
            "Epoch 4/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0844 - acc: 0.9737\n",
            "Epoch 5/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0785 - acc: 0.9756\n",
            "Epoch 6/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0645 - acc: 0.9801\n",
            "Epoch 7/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0660 - acc: 0.9795\n",
            "Epoch 8/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0620 - acc: 0.9809\n",
            "Epoch 9/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0586 - acc: 0.9817\n",
            "Epoch 10/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0526 - acc: 0.9831\n",
            "Epoch 11/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0541 - acc: 0.9832\n",
            "Epoch 12/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0559 - acc: 0.9823\n",
            "Epoch 13/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0475 - acc: 0.9850\n",
            "Epoch 14/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0472 - acc: 0.9852\n",
            "Epoch 15/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0478 - acc: 0.9853\n",
            "Epoch 1/15\n",
            "40000/40000 [==============================] - 2s 58us/step - loss: 0.3873 - acc: 0.8768\n",
            "Epoch 2/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.1394 - acc: 0.9576\n",
            "Epoch 3/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.1123 - acc: 0.9656\n",
            "Epoch 4/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0958 - acc: 0.9699\n",
            "Epoch 5/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0872 - acc: 0.9718\n",
            "Epoch 6/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0801 - acc: 0.9744\n",
            "Epoch 7/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0749 - acc: 0.9768\n",
            "Epoch 8/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0728 - acc: 0.9773\n",
            "Epoch 9/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0699 - acc: 0.9778\n",
            "Epoch 10/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0657 - acc: 0.9793\n",
            "Epoch 11/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0596 - acc: 0.9807\n",
            "Epoch 12/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0634 - acc: 0.9795\n",
            "Epoch 13/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0567 - acc: 0.9814\n",
            "Epoch 14/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0582 - acc: 0.9822\n",
            "Epoch 15/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0563 - acc: 0.9818\n",
            "Epoch 1/15\n",
            "40000/40000 [==============================] - 2s 58us/step - loss: 0.3567 - acc: 0.8864\n",
            "Epoch 2/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.1494 - acc: 0.9527\n",
            "Epoch 3/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.1257 - acc: 0.9609\n",
            "Epoch 4/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.1043 - acc: 0.9673\n",
            "Epoch 5/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0975 - acc: 0.9704\n",
            "Epoch 6/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0921 - acc: 0.9709\n",
            "Epoch 7/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0830 - acc: 0.9745\n",
            "Epoch 8/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0835 - acc: 0.9736\n",
            "Epoch 9/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0805 - acc: 0.9754\n",
            "Epoch 10/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0748 - acc: 0.9775\n",
            "Epoch 11/15\n",
            "40000/40000 [==============================] - 1s 36us/step - loss: 0.0729 - acc: 0.9771\n",
            "Epoch 12/15\n",
            "40000/40000 [==============================] - 1s 37us/step - loss: 0.0708 - acc: 0.9780\n",
            "Epoch 13/15\n",
            "40000/40000 [==============================] - 1s 37us/step - loss: 0.0704 - acc: 0.9780\n",
            "Epoch 14/15\n",
            "40000/40000 [==============================] - 2s 38us/step - loss: 0.0676 - acc: 0.9789\n",
            "Epoch 15/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.0689 - acc: 0.9782\n",
            "Epoch 1/15\n",
            "40000/40000 [==============================] - 3s 65us/step - loss: 0.6072 - acc: 0.8011\n",
            "Epoch 2/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.1569 - acc: 0.9530\n",
            "Epoch 3/15\n",
            "40000/40000 [==============================] - 2s 42us/step - loss: 0.1171 - acc: 0.9638\n",
            "Epoch 4/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0952 - acc: 0.9709\n",
            "Epoch 5/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.0844 - acc: 0.9745\n",
            "Epoch 6/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.0746 - acc: 0.9767\n",
            "Epoch 7/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.0667 - acc: 0.9800\n",
            "Epoch 8/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0623 - acc: 0.9810\n",
            "Epoch 9/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.0600 - acc: 0.9818\n",
            "Epoch 10/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0584 - acc: 0.9827\n",
            "Epoch 11/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0517 - acc: 0.9842\n",
            "Epoch 12/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0487 - acc: 0.9850\n",
            "Epoch 13/15\n",
            "40000/40000 [==============================] - 2s 42us/step - loss: 0.0466 - acc: 0.9855\n",
            "Epoch 14/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.0477 - acc: 0.9850\n",
            "Epoch 15/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0411 - acc: 0.9869\n",
            "Epoch 1/15\n",
            "40000/40000 [==============================] - 3s 65us/step - loss: 0.7014 - acc: 0.7667\n",
            "Epoch 2/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.3082 - acc: 0.9045\n",
            "Epoch 3/15\n",
            "40000/40000 [==============================] - 2s 42us/step - loss: 0.2613 - acc: 0.9197\n",
            "Epoch 4/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.2352 - acc: 0.9266\n",
            "Epoch 5/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.2229 - acc: 0.9308\n",
            "Epoch 6/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.2084 - acc: 0.9357\n",
            "Epoch 7/15\n",
            "40000/40000 [==============================] - 2s 39us/step - loss: 0.1982 - acc: 0.9389\n",
            "Epoch 8/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.1912 - acc: 0.9398\n",
            "Epoch 9/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.1896 - acc: 0.9399\n",
            "Epoch 10/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.1798 - acc: 0.9425\n",
            "Epoch 11/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.1757 - acc: 0.9433\n",
            "Epoch 12/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.1756 - acc: 0.9441\n",
            "Epoch 13/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.1688 - acc: 0.9459\n",
            "Epoch 14/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.1649 - acc: 0.9470\n",
            "Epoch 15/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.1631 - acc: 0.9483\n",
            "Epoch 1/15\n",
            "40000/40000 [==============================] - 3s 67us/step - loss: 0.3035 - acc: 0.9039\n",
            "Epoch 2/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.1032 - acc: 0.9692\n",
            "Epoch 3/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.0776 - acc: 0.9768\n",
            "Epoch 4/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0622 - acc: 0.9805\n",
            "Epoch 5/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0530 - acc: 0.9837\n",
            "Epoch 6/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0493 - acc: 0.9843\n",
            "Epoch 7/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0420 - acc: 0.9878\n",
            "Epoch 8/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0336 - acc: 0.9894\n",
            "Epoch 9/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0381 - acc: 0.9880\n",
            "Epoch 10/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0349 - acc: 0.9895\n",
            "Epoch 11/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0318 - acc: 0.9905\n",
            "Epoch 12/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.0302 - acc: 0.9911\n",
            "Epoch 13/15\n",
            "40000/40000 [==============================] - 2s 41us/step - loss: 0.0292 - acc: 0.9913\n",
            "Epoch 14/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0260 - acc: 0.9925\n",
            "Epoch 15/15\n",
            "40000/40000 [==============================] - 2s 40us/step - loss: 0.0248 - acc: 0.9922\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.2830 - acc: 0.9113\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1197 - acc: 0.9642\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0979 - acc: 0.9707\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0848 - acc: 0.9749\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0821 - acc: 0.9749\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0757 - acc: 0.9775\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.0718 - acc: 0.9775\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0722 - acc: 0.9777\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0629 - acc: 0.9811\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0604 - acc: 0.9814\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0622 - acc: 0.9800\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0612 - acc: 0.9814\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0569 - acc: 0.9829\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0556 - acc: 0.9829\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0555 - acc: 0.9826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EHjorOLOij9",
        "colab_type": "code",
        "outputId": "99cf25c5-b6a1-41f2-ff98-a603be027b52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "best_model_cnn = validator.best_estimator_.model\n",
        "metric_names_cnn = best_model_cnn.metrics_names\n",
        "metric_values_cnn = best_model_cnn.evaluate(x_test_cnn, y_test_cnn)\n",
        "for metric, value in zip(metric_names_cnn, metric_values_cnn):\n",
        "    print(metric, ': ', value)\n",
        "    "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 96us/step\n",
            "loss :  0.03398493984423076\n",
            "acc :  0.9897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENRsdaLg0m5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5cba53c-03e1-48ce-f421-2a5676fc4af2"
      },
      "source": [
        "Result1.update(cnn_acu = metric_values_cnn[1]*100)\n",
        "Result1"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cnn_acu': 98.97, 'mlp_accu': 0.9371, 'rf_accu': 90.06}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAI2pPDXqW5D",
        "colab_type": "text"
      },
      "source": [
        "### AutoEncoder to Find Best Learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SUAyg2UTB16",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "296e5c87-0641-4b15-9367-5618848e0c98"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train_ae,_), (x_test_ae, _) = fashion_mnist.load_data()\n",
        "\n",
        "x_train_ae = x_train_ae.astype('float32') / 255.\n",
        "x_test_ae = x_test_ae.astype('float32') / 255.\n",
        "x_train_ae = np.reshape(x_train_ae, (len(x_train_ae), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test_ae = np.reshape(x_test_ae, (len(x_test_ae), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_train_ae.shape\n",
        "#y_train = keras.utils.to_categorical(y_train, 10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 4us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RJHFIr_fhIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_autoencoder(lr=0.01):\n",
        "  from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "  from keras.models import Model\n",
        "  from keras import backend as K\n",
        "\n",
        "  input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "  x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "  x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "  x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "  x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "  x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "  encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "  # at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "  x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "  x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "  x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "  decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "  autoencoder = Model(input_img, decoded)\n",
        "  autoencoder.compile(optimizer = keras.optimizers.Adadelta(lr=lr),loss = 'binary_crossentropy')\n",
        "  \n",
        "  return autoencoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3JDMOQAT9no",
        "colab_type": "code",
        "outputId": "dd2519dc-ac3a-4dc5-c8ce-2de64ff83f4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "ae = cnn_autoencoder()\n",
        "parameter = { 'lr': [0.001,0.1]}\n",
        "comb = ParameterGrid(parameter)\n",
        "print(comb)\n",
        "analysis = []\n",
        "for param in ParameterGrid(parameter):\n",
        "  print(param)\n",
        "  \n",
        "  #history = {}\n",
        "  history = ae.fit(x_train_ae,x_train_ae, epochs=5, batch_size = 126,shuffle = True ,validation_data = (x_test_ae,x_test_ae))\n",
        "  \n",
        "  print(min(history.history['loss']))\n",
        "  print(min(history.history['val_loss']))\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sklearn.model_selection._search.ParameterGrid object at 0x7f63558ca390>\n",
            "{'lr': 0.001}\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.6831 - val_loss: 0.6574\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.5885 - val_loss: 0.4862\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.4329 - val_loss: 0.3948\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.3786 - val_loss: 0.3721\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.3656 - val_loss: 0.3638\n",
            "0.36563389434814453\n",
            "0.36377939326763153\n",
            "{'lr': 0.1}\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.3589 - val_loss: 0.3585\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.3544 - val_loss: 0.3544\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.3508 - val_loss: 0.3512\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.3478 - val_loss: 0.3484\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.3453 - val_loss: 0.3460\n",
            "0.3452665518462658\n",
            "0.34603440660238266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBMOhMfv9tVl",
        "colab_type": "text"
      },
      "source": [
        "The loss for lr 0.1 is low so we trained auotencoder with learning rate of 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVc3_z2z936Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "input_img_ae = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img_ae)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "encoder = Model(input_img_ae, encoded)\n",
        "\n",
        "  # at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img_ae, decoded)\n",
        "autoencoder.compile(optimizer = keras.optimizers.Adadelta(lr=0.1),loss = 'binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5lCkDuv-CSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "e91bf2f8-c586-48a3-845f-b6ee03ca2115"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=2, random_state=None, shuffle=False)\n",
        "val_score = []\n",
        "  \n",
        "for train_index,  test_index in kf.split(x_train_ae):\n",
        "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "  X_train,X_test = x_train_ae[train_index],x_train_ae[test_index] \n",
        "  #val_score = []\n",
        "  \n",
        "  history = autoencoder.fit(X_train,X_train, epochs = 10,batch_size = 126, shuffle = True, validation_data = (X_test,X_test) )\n",
        "  score = autoencoder.evaluate(x_train_ae,x_train_ae)\n",
        "  val_score.append((score,autoencoder))\n",
        "  \n",
        "  \n",
        "  \n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [30000 30001 30002 ... 59997 59998 59999] TEST: [    0     1     2 ... 29997 29998 29999]\n",
            "Train on 30000 samples, validate on 30000 samples\n",
            "Epoch 1/10\n",
            "30000/30000 [==============================] - 4s 133us/step - loss: 0.5215 - acc: 0.4869 - val_loss: 0.3829 - val_acc: 0.4909\n",
            "Epoch 2/10\n",
            "30000/30000 [==============================] - 2s 77us/step - loss: 0.3675 - acc: 0.4962 - val_loss: 0.3539 - val_acc: 0.4969\n",
            "Epoch 3/10\n",
            "30000/30000 [==============================] - 2s 77us/step - loss: 0.3513 - acc: 0.4977 - val_loss: 0.3452 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "30000/30000 [==============================] - 2s 77us/step - loss: 0.3445 - acc: 0.4985 - val_loss: 0.3408 - val_acc: 0.4971\n",
            "Epoch 5/10\n",
            "30000/30000 [==============================] - 2s 77us/step - loss: 0.3391 - acc: 0.4992 - val_loss: 0.3352 - val_acc: 0.4986\n",
            "Epoch 6/10\n",
            "30000/30000 [==============================] - 2s 77us/step - loss: 0.3341 - acc: 0.4999 - val_loss: 0.3304 - val_acc: 0.5007\n",
            "Epoch 7/10\n",
            "30000/30000 [==============================] - 2s 76us/step - loss: 0.3301 - acc: 0.5005 - val_loss: 0.3272 - val_acc: 0.5011\n",
            "Epoch 8/10\n",
            "30000/30000 [==============================] - 2s 77us/step - loss: 0.3265 - acc: 0.5011 - val_loss: 0.3248 - val_acc: 0.5006\n",
            "Epoch 9/10\n",
            "30000/30000 [==============================] - 2s 76us/step - loss: 0.3239 - acc: 0.5015 - val_loss: 0.3221 - val_acc: 0.5015\n",
            "Epoch 10/10\n",
            "30000/30000 [==============================] - 2s 76us/step - loss: 0.3215 - acc: 0.5018 - val_loss: 0.3212 - val_acc: 0.5036\n",
            "60000/60000 [==============================] - 4s 62us/step\n",
            "TRAIN: [    0     1     2 ... 29997 29998 29999] TEST: [30000 30001 30002 ... 59997 59998 59999]\n",
            "Train on 30000 samples, validate on 30000 samples\n",
            "Epoch 1/10\n",
            "30000/30000 [==============================] - 2s 76us/step - loss: 0.3192 - acc: 0.5023 - val_loss: 0.3194 - val_acc: 0.5007\n",
            "Epoch 2/10\n",
            "30000/30000 [==============================] - 2s 76us/step - loss: 0.3176 - acc: 0.5025 - val_loss: 0.3167 - val_acc: 0.5023\n",
            "Epoch 3/10\n",
            "30000/30000 [==============================] - 2s 78us/step - loss: 0.3161 - acc: 0.5027 - val_loss: 0.3153 - val_acc: 0.5025\n",
            "Epoch 4/10\n",
            "30000/30000 [==============================] - 2s 78us/step - loss: 0.3147 - acc: 0.5029 - val_loss: 0.3145 - val_acc: 0.5017\n",
            "Epoch 5/10\n",
            "30000/30000 [==============================] - 2s 77us/step - loss: 0.3133 - acc: 0.5030 - val_loss: 0.3127 - val_acc: 0.5031\n",
            "Epoch 6/10\n",
            "30000/30000 [==============================] - 2s 78us/step - loss: 0.3121 - acc: 0.5032 - val_loss: 0.3130 - val_acc: 0.5015\n",
            "Epoch 7/10\n",
            "30000/30000 [==============================] - 2s 77us/step - loss: 0.3112 - acc: 0.5033 - val_loss: 0.3110 - val_acc: 0.5024\n",
            "Epoch 8/10\n",
            "30000/30000 [==============================] - 2s 78us/step - loss: 0.3103 - acc: 0.5034 - val_loss: 0.3117 - val_acc: 0.5046\n",
            "Epoch 9/10\n",
            "30000/30000 [==============================] - 2s 76us/step - loss: 0.3094 - acc: 0.5035 - val_loss: 0.3097 - val_acc: 0.5022\n",
            "Epoch 10/10\n",
            "30000/30000 [==============================] - 2s 78us/step - loss: 0.3087 - acc: 0.5035 - val_loss: 0.3084 - val_acc: 0.5030\n",
            "60000/60000 [==============================] - 4s 60us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z6leMIfTuPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8f2a33a-b41c-45b4-fb13-2723ebcf08ad"
      },
      "source": [
        "val_score\n",
        "\n",
        "sorted_val_score = sorted(val_score, key = lambda a:(a[0]), reverse = True)\n",
        "autoencoder = sorted_val_score[0].__getitem__(1)\n",
        "autoencoder"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7f635518b3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0pKljeCWJ23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "cdaf4ef4-3b6e-4cf4-9669-492be8d51eda"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 14, 14, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 7, 7, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 7, 7, 8)           584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 4, 4, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 8, 8, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 14, 14, 16)        1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 28, 28, 1)         145       \n",
            "=================================================================\n",
            "Total params: 4,385\n",
            "Trainable params: 4,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPzkN8RqDL8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "39b4c6c0-c25a-49cf-be6b-4cb363079928"
      },
      "source": [
        "\n",
        "encoder_train  = Model(autoencoder.input, autoencoder.layers[-8].output)\n",
        "\n",
        "encoder_train.summary()\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 14, 14, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 7, 7, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 7, 7, 8)           584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 4, 4, 8)           0         \n",
            "=================================================================\n",
            "Total params: 1,904\n",
            "Trainable params: 1,904\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZTowZrHFP_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "0124c8f3-d540-4571-a218-0e5ad9d4a523"
      },
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i+1)\n",
        "    plt.imshow(encoder_train_image[i].reshape(4, 4 * 8).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABEIAAAHBCAYAAABt3h6oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XuQnndd///3vedks5tkk02zJSE9\nJSUhpdishYp8gUILBaQgHhAYB0TEOjLOCIJoFREZmKIDchimwygM6gCOyqCClGNhBgs1LfRE2zRt\nt6Vp0qQ5bpLNHq/vH9/5zfz+6C6+PzQb7v08Hv/ePve6miuf3XtfuRlbTdMEAAAAQA06zvQNAAAA\nACwWQwgAAABQDUMIAAAAUA1DCAAAAFANQwgAAABQDUMIAAAAUI2uhV5stVpF/791u7oW/LJP6KKL\nLiq5VBw7dqyou//++x9vmma4KG4zg4ODzfBw/j+1t7c33Rw5ciTdRET09fWlmwMHDsT4+Hir6IJt\nZtmyZc3AwEC6m5qaSjcl5zcioru7u6jbt29fNWdxzZo1zcaNG9PdxMREujl16lS6iYgYHBxMN3v2\n7IlDhw5VcxZL/oxmZ2fTTcn3xYiI5cuXF3X33XdfNWdx1apVzcjISLrr7OxMNz09PekmIqKjI/9v\nVWNjY/H4449XcRZL36OuX78+3ZS8h4qIuOuuu4q6ubm5as7i4OBgs27dunRX8v2x9Htqyc/gRx99\nNA4fPlzNWWy18v+pTZM/whdccEG6iYgoeQ/98MMPV/P9NGJxn+P27dvTTUTZ76YL/Vz8ib/xlPyB\nrF69Ot185zvfSTcREd/85jeLuquvvvqhorANDQ8Px/vf//50d95556WbL33pS+kmIuL8889PN3/+\n539edK12NDAwEK9+9avT3Z49e9LNmjVr0k1ExFOe8pSi7n3ve181Z3Hjxo3x1a9+Nd3deeed6Wb3\n7t3pJiLiBS94Qbr55V/+5aJrtaPBwcF43etel+5KRuKtW7emm4jyf1i46qqrqjmLIyMj8elPfzrd\nlby/2bBhQ7qJKBu0RkdHi67VrkqGqTe96U3p5i1veUu6iSh/s3/s2LFqzuK6deviuuuuS3dPf/rT\n082FF16YbiIibrvttnTz2te+tuha7ajVahX9gjozM5NuPvShD6WbiIjLL7883fziL/5i0bXaVavV\nKvpHzZJ/dP23f/u3dBMRsXnz5nSz0M9F/9MYAAAAoBqGEAAAAKAahhAAAACgGoYQAAAAoBqGEAAA\nAKAahhAAAACgGoYQAAAAoBqGEAAAAKAahhAAAACgGoYQAAAAoBqGEAAAAKAahhAAAACgGq2maeZ/\nsdWa/8X2d0vTNKNn+iYWw1J+jk3TtM70PSyGpfwMw1lcEpzFJcFZXAKcxSXBWVwCajqLHR2L82/r\nc3Nzi3Kd/08tzzCizrPoEyEAAABANQwhAAAAQDUMIQAAAEA1DCEAAABANQwhAAAAQDUMIQAAAEA1\nDCEAAABANQwhAAAAQDUMIQAAAEA1DCEAAABANQwhAAAAQDUMIQAAAEA1us70DQAAwGJotVrppmma\n03AnsHTMzc2d6VuANJ8IAQAAAKphCAEAAACqYQgBAAAAqmEIAQAAAKphCAEAAACqYQgBAAAAqmEI\nAQAAAKphCAEAAACqYQgBAAAAqmEIAQAAAKphCAEAAACqYQgBAAAAqmEIAQAAAKrRtdCLnZ2dsWLF\nivQXfclLXpJuJicn001ExA9/+MOibmxsrKhrRwMDA3HppZemu+np6XRz6NChdBMRcd9996Wbqamp\nomu1o+7u7hgeHk53Jee31IEDB4q6w4cPP8l38rNrcHAwnvOc56S7U6dOpZvZ2dl0ExFx2223pZvj\nx48XXasd9fb2xoYNG9Jdq9VKN6Xn99577y3qJiYmirp2tGrVqnjhC1+Y7jo68v9+VPLsIyL+8z//\nM92UfK9oVz09PbF+/fp0d84556Sbhx9+ON1ERJw8ebKo279/f1HXjgYGBmJ0dDTddXUt+CvMEyo5\nvxFlvzPU9HtG6XvUkvN7/vnnp5uIiG9/+9vppvR3mnbV0dERy5YtS3cl53dwcDDdRETcfPPN6ebg\nwYPzvuYTIQAAAEA1DCEAAABANQwhAAAAQDUMIQAAAEA1DCEAAABANQwhAAAAQDUMIQAAAEA1DCEA\nAABANQwhAAAAQDUMIQAAAEA1DCEAAABANQwhAAAAQDW6FnpxdnY2jh8/nv6iN954Y7r5wAc+kG4i\nIjZu3FjUffSjHy3q2lHTNDE5OZnu1q9fn26+973vpRt+sqZpYmZmJt3dd9996aazszPdRES0Wq2i\nribT09OxZ8+edFfyffjEiRPpJiJi7dq16ebUqVNF12pHk5OT8cADD6S7pmlOw908sd7e3kW7Vrua\nm5srOlfnnntuuhkcHEw3EREvfelL0803vvGNomu1o+np6di7d2+66+jI/xvgK1/5ynQTEfGZz3ym\nqKvJ3Nxc0XvUbdu2pZvS3xnuv//+dHPw4MGia7Wj0veou3btSjdnnXVWuomIuPLKK9PNl7/85aJr\ntbOS9yrf/va3080f//Efp5uIiOc973np5sMf/vC8r/lECAAAAFANQwgAAABQDUMIAAAAUA1DCAAA\nAFANQwgAAABQDUMIAAAAUA1DCAAAAFANQwgAAABQDUMIAAAAUA1DCAAAAFANQwgAAABQDUMIAAAA\nUA1DCAAAAFCNVtM0877Y2dnZrFixIv1FL7300nQzNjaWbiIidu/eXdRFxC1N04yWxu2kp6enGR4e\nTnePPvroabibJ1fTNK0zfQ+Lobu7uxkaGkp3c3Nz6WZ2djbd/DTdsWPHqjmLrVar6ezsTHcLfZ+e\nz8DAQLqJiDh69GhRV8tZ7OjoaLq6utLdYp7Fn0I1Z7H0e+rBgwfTzWI/x1rOYnd3d7N27dp0V9Lc\nc8896SYioqOj7N8bp6amqjmLPT09zbp169Ld/v3708309HS6+WnUchZ7e3ub9evXp7uS5z4yMpJu\nIiJuuOGGdDM9PR1zc3NVPMOI//d7f39/f7r7uZ/7uXRz8uTJdBMRsXPnzqJuvrPoEyEAAABANQwh\nAAAAQDUMIQAAAEA1DCEAAABANQwhAAAAQDUMIQAAAEA1DCEAAABANQwhAAAAQDUMIQAAAEA1DCEA\nAABANQwhAAAAQDUMIQAAAEA1DCEAAABANVpN08z/Yqs1/4tPsmuvvbao27RpU1H35je/+ZamaUaL\n4jbT3d3drFmzJt1ddNFF6eb2229PNxERg4OD6ebHP/5xnDp1qlV0wTbT2dnZ9Pf3p7vx8fHTcDdP\nbGRkpKjbu3dvNWexr6+v2bhxY7rr6elJNw8++GC6iYjYtm1burn77rvjxIkTzuICTpw4kW66urrS\nTUTEli1biro777yzmrO4bNmy5rzzzkt3q1evTjcrVqxINxERQ0ND6eaGG26IgwcPVnEWF/M96u//\n/u8XdZ/85CeLusnJyWrOYldXV1PyHvC5z31uuik5vxERC/2uNJ8vfelL8fjjj1dzFlut/H9qyZ9r\nqZLfM//u7/4uHn300SqeYUT599SS9yo7duwouVS8/vWvTzfXXXddPPzww0/4HH0iBAAAAKiGIQQA\nAACohiEEAAAAqIYhBAAAAKiGIQQAAACohiEEAAAAqIYhBAAAAKiGIQQAAACohiEEAAAAqIYhBAAA\nAKiGIQQAAACohiEEAAAAqEaraZr5X2y1mq6urvQXnZ2dTTcL3cdpckvTNKOLfdEzodVqLfof7mJp\nmqZ1pu9hMSzlZxjO4pLgLC4JzuISUNNZ7OzsTHcl71FLdXSU/Xvj3Nycs/gzpLu7O93MzMzE3Nxc\nFWexs7Oz6evrS3clf65Hjx5NNz+NWr6fRpT/3l/yO/xifh+OmP85+kQIAAAAUA1DCAAAAFANQwgA\nAABQDUMIAAAAUA1DCAAAAFANQwgAAABQDUMIAAAAUA1DCAAAAFANQwgAAABQDUMIAAAAUA1DCAAA\nAFANQwgAAABQDUMIAAAAUI2uhV4cHh6OX//1X09/0Xe/+93ppqOjbJP5yle+UtS97nWvK+ra0aZN\nm+Laa69NdydPnkw3W7duTTcREVdccUW6GR0dLbpWO9qxY0fs3Lkz3d1+++3pZmxsLN1ElD+Ppzzl\nKUVdO7r44ovja1/7Wro7evRoujly5Ei6iSh7jjWdxfPPPz/+5m/+Jt0NDw+nm9WrV6ebiPLvw61W\nq6hrR0972tPiU5/6VLrr7e1NN5s3b043ERH79u1LN6961auKrtWumqZJN3fccUe62b59e7qJiFi1\nalVRV/I9v11t2bIlrr/++nRX8uyf9axnpZuIiHe9613p5nOf+1zRtdrR5s2b4+///u/T3U033ZRu\n3va2t6WbiIgHHngg3Vx99dVF12pXg4OD8exnPzvdXXjhhenm5S9/ebqJKPt5+opXvGLe13wiBAAA\nAKiGIQQAAACohiEEAAAAqIYhBAAAAKiGIQQAAACohiEEAAAAqIYhBAAAAKiGIQQAAACohiEEAAAA\nqIYhBAAAAKiGIQQAAACohiEEAAAAqEaraZr5X2y15n+x/d3SNM3omb6JxbCUn2PTNK0zfQ+LYSk/\nw3AWlwRncUlwFpcAZ3FJcBaXAGfxZ0dfX1+6mZycjLm5uSqeYcTiPscLLrigqDv77LPTza233hrj\n4+NP+Bx9IgQAAACohiEEAAAAqIYhBAAAAKiGIQQAAACohiEEAAAAqIYhBAAAAKiGIQQAAACohiEE\nAAAAqIYhBAAAAKiGIQQAAACohiEEAAAAqIYhBAAAAKiGIQQAAACoRteZvgEAAAA4HU6dOnWmb4H/\nn927dy9qNx+fCAEAAACqYQgBAAAAqmEIAQAAAKphCAEAAACqYQgBAAAAqmEIAQAAAKphCAEAAACq\nYQgBAAAAqmEIAQAAAKphCAEAAACqYQgBAAAAqmEIAQAAAKphCAEAAACq0bXQiwMDAzE6Opr+oidO\nnMjfSNeCtzKv/fv3F3W7d+8u6tpRf39/XHzxxelu06ZN6ebQoUPpJiLilltuSTdHjhwpulY7Wr16\ndVxxxRXpbm5uLt0cPHgw3URE3HXXXUVd6RluR2vWrImXv/zl6a7k++Ojjz6abiIi7rjjjnTz2GOP\nFV2rHQ0ODsZll12W7pqmSTcl5zci4u677y7q9uzZU9S1o6GhoXjxi1+c7kqeSenPxfvvvz/dPPLI\nI0XXakfLly+Pbdu2pbuS76dTU1PpJqL8TNX0PXXFihVFv2uUOHXqVFE3Pj6ebkrOb7tavXp1vPCF\nL0x3MzMz6abkZ2lExNjYWLrZtWtX0bXaVW9vb2zcuDHdrVy5Mt2sWbMm3UREHDt2LN0s9L7WJ0IA\nAACAahhCAAAAgGoYQgAAAIBqGEIAAACAahhCAAAAgGoYQgAAAIBqGEIAAACAahhCAAAAgGoYQgAA\nAIBqGEIAAACAahhCAAAAgGoYQgAAAIBqdC304uTkZDz44IPpL7pjx45085rXvCbdRETcddddRd1f\n/MVfFHXtaPny5fGMZzwj3W3ZsiXdTE1NpZuIiP/zf/5Puvn4xz9edK12tGbNmnjDG96Q7u6+++50\nc/To0XQTEfHc5z63qPvLv/zLoq4drVq1Kq6++up0Nzc3l2727t2bbiIifuEXfiHdfOITnyi6Vjsa\nGBiIyy+/PN0tX778NNzNE7vyyiuLune84x1P8p387Orv7y/6uz40NJRuBgcH001ExD333JNu/vZv\n/7boWu3o5MmTceutt6a7N77xjenmRS96UbqJqOtMlRoYGCh6/7Bhw4Z009W14K898/rv//7vdPPY\nY48VXasdTU5OxsMPP5zuSt7bbNu2Ld1ERLzlLW9JNx/4wAeKrtWupqeni/7eHj9+PN288pWvTDcR\nEStXrkw3H/zgB+d9zSdCAAAAgGoYQgAAAIBqGEIAAACAahhCAAAAgGoYQgAAAIBqGEIAAACAahhC\nAAAAgGoYQgAAAIBqGEIAAACAahhCAAAAgGoYQgAAAIBqGEIAAACAahhCAAAAgGq0mqaZ98Xu7u5m\naGgo/UWf/vSnp5sf//jH6SYiYvfu3UVdRNzSNM1oadxO+vv7m+3bt6e7m2+++TTczZOraZrWmb6H\nxdDb29usX78+3R04cCDddHZ2ppuIiOPHjxd1UdFZHBgYaHbs2JHubrrppnRT+hwnJiaKuprO4oYN\nG9Ldnj170s3s7Gy6iYiYmZkp6qKiszg4ONg861nPSndf//rXT8PdPLlqOYv9/f3Ntm3b0t0FF1yQ\nbj73uc+lm59SVWdxdDT/n/qtb33rNNzNk6uWs1j6++K6devSzeWXX55uIiI+8pGPFHW1PMOIiI6O\njqanpyfd/eqv/mq66e7uTjcREZ/61KeKuvmeo0+EAAAAANUwhAAAAADVMIQAAAAA1TCEAAAAANUw\nhAAAAADVMIQAAAAA1TCEAAAAANUwhAAAAADVMIQAAAAA1TCEAAAAANUwhAAAAADVMIQAAAAA1eha\n6MWZmZnYv39/+os+9alPTTd/8id/km4iIkZGRoq6q666qqhrR6tXr45XvvKV6e7FL35xuunp6Uk3\nERFr165NN+9///uLrtWOzjvvvPjMZz6T7r7whS+km+PHj6ebiIihoaGi7j3veU9R1442bNgQH/zg\nB9PdPffck27GxsbSTUTE1q1b08073/nOomu1o5UrV8aVV16Z7lavXp1uuroW/BE9r7PPPruou+aa\na4q6djQ0NBSvec1r0l1J09/fn24iIs4999x084Y3vKHoWu3o5MmTsXPnznTX19eXbr74xS+mm4iI\n3/md3ynqHnvssaKuHQ0MDMTll1+e7n7t134t3WzYsCHdREScOHEi3ZT+XtOOSn9f3LhxY7q54447\n0k1ExKc+9al0U9P704iIpmlicnIy3X3rW99KN89//vPTTUTZ7zVvf/vb533NJ0IAAACAahhCAAAA\ngGoYQgAAAIBqGEIAAACAahhCAAAAgGoYQgAAAIBqGEIAAACAahhCAAAAgGoYQgAAAIBqGEIAAACA\nahhCAAAAgGoYQgAAAIBqGEIAAACAarSappn/xVar6erqSn/RmZmZn+aeFsstTdOMnumbWAytVmv+\nh9zmmqZpnel7WAzd3d3N2rVr092+fftOw9086ZzFJaCWs9gOz7C7u7uom56edhaXgJrOYkdH/t/z\n5ubmTsPdPLFly5YVdRMTE87iz5ChoaF0c/To0ZiZmanmLJ7pe/hJtm/fnm52794dExMTVTzDiMV9\njqOjZd/eRkZG0s13vvOdOHLkyBM+R58IAQAAAKphCAEAAACqYQgBAAAAqmEIAQAAAKphCAEAAACq\nYQgBAAAAqmEIAQAAAKphCAEAAACqYQgBAAAAqmEIAQAAAKphCAEAAACqYQgBAAAAqtG10Itr1qyJ\nX/qlX0p/0WuvvTbdnH/++ekmIuJjH/tYUffWt761qGtHGzdujD/6oz9Kd9u3b083jz/+eLqJiNi8\neXO6ee1rX1t0rXZ0zjnnxIc+9KF0NzY2lm5mZ2fTTUTEihUrirrf/u3fLura0datW+Mf//Ef092+\nffvSzbZt29JNRMSmTZvSzc///M8XXasdrV27Nq6++up0Nzg4mG4uueSSdFN6rYgo+u9qV1u3bo1/\n+qd/Sndr1qxJN3Nzc+kmIuLQoUPp5vWvf33RtdpVyZ/tN7/5zXTzrGc9K91ERIyMjBR1ExMTRV07\n2rx5c3zkIx9Jd2eddVa6Wb9+fbqJiDhx4kS6edWrXlV0rXZ00UUXxb//+7+nu3POOSfdHDhwIN1E\nRPze7/1eutmzZ0/RtdrVxo0b4x3veEe6u/DCC9PNvffem24iIj7/+c+nm4V+r/GJEAAAAKAahhAA\nAACgGoYQAAAAoBqGEAAAAKAahhAAAACgGoYQAAAAoBqGEAAAAKAahhAAAACgGoYQAAAAoBqGEAAA\nAKAahhAAAACgGoYQAAAAoBqGEAAAAKAaraZp5n+x1WparVb6iy70NX+G3NI0zeiZvonF0Gq1Fu2B\njI6W/ZGuWbMm3dx0001x9OjR/F/QNrRx48bmbW97W7q79957082hQ4fSTUREZ2dnUffZz362mrO4\nbt265tWvfnW6m5ycTDcTExPpJiLiscceSzc7d+6MY8eOVXEWzz777ObNb35zuiv5uVj6s/TIkSNF\n3cc+9rFqzmJ3d3ezdu3adLdv377TcDdPrqZpqjiLHR0dTXd3d7qbmpo6DXfzpKvmLHZ0dDRdXV3p\nbnp6+jTczZOrlrO4mL9n9Pb2FnUXXXRRuvnRj34UJ06cqOIZRizuc9yyZUtRd/7556eb7373u/P+\nvugTIQAAAEA1DCEAAABANQwhAAAAQDUMIQAAAEA1DCEAAABANQwhAAAAQDUMIQAAAEA1DCEAAABA\nNQwhAAAAQDUMIQAAAEA1DCEAAABANQwhAAAAQDUMIQAAAEA1Wk3TzP9iqzX/i+3vlqZpRs/0TSyG\npfwcm6Zpnel7WAxL+RmGs7gkOItLgrO4BDiLS4KzuAQ4i+2vlmcYUedz9IkQAAAAoBqGEAAAAKAa\nhhAAAACgGoYQAAAAoBqGEAAAAKAahhAAAACgGoYQAAAAoBqGEAAAAKAahhAAAACgGoYQAAAAoBqG\nEAAAAKAahhAAAACgGl0Lvdjf3x8XX3xx+oueddZZ6WZ8fDzdREQ88sgjRd0999xT1LWjgYGBuPTS\nS9NdyTNZtWpVuomI2LNnT7q5//77i67VjtatWxe/8Ru/ke7279+fbkrP4sMPP1zU3X777UVdO1q5\ncmU873nPS3fr169PN7Ozs+kmouxc7dy5s+ha7aj0Ga5ZsybdnDp1Kt1ERNx1111FXU1ncXh4OF79\n6lenu1arlW727duXbiLKzuJ9991XdK12tHz58ti6dWu6KzmLR44cSTcREQ8++GBRd+DAgaKuHa1e\nvTquvPLKdNfX15dupqam0k1ExA9+8IN0MzY2VnStdrRq1ap4/vOfn+7Wrl2bbkp/Ts3NzaWbH/3o\nR0XXalcDAwPx7Gc/O92tXr063dx0003pJqLsve1C3099IgQAAACohiEEAAAAqIYhBAAAAKiGIQQA\nAACohiEEAAAAqIYhBAAAAKiGIQQAAACohiEEAAAAqIYhBAAAAKiGIQQAAACohiEEAAAAqIYhBAAA\nAKiGIQQAAACoRteCL3Z1xerVq9Nf9CUveUm6Ofvss9NNRMTNN99c1L33ve8t6tpRf39/XHrppelu\ndnY23QwMDKSbiIjOzs508/GPf7zoWu1oeHg4rrnmmnRXcj4eeuihdBMRMTo6WtTdfvvtRV07Wrdu\nXdFzfOCBB9JNR0fZzr1jx450U3J/7aq7uzvOOuusdLdq1ap0s27dunQTEXHxxRcXdTWdxeXLlxf9\nXBwcHEw3TdOkm4iIQ4cOpZv3ve99RddqRydPnowf/vCH6e5d73pXunnmM5+ZbiIi/vAP/7Coq0lf\nX1887WlPS3dr1qxJNytXrkw3ERHbtm1LN5/4xCeKrtWOenp64pxzzkl3F154YboZHh5ONxERc3Nz\n6eaRRx4pula7mpubi5MnT6a75z//+UXXKrFv3750c+zYsXlf84kQAAAAoBqGEAAAAKAahhAAAACg\nGoYQAAAAoBqGEAAAAKAahhAAAACgGoYQAAAAoBqGEAAAAKAahhAAAACgGoYQAAAAoBqGEAAAAKAa\nhhAAAACgGl0/6f+goyO/lfzu7/5uummaJt3wv3Py5Mm49dZb093OnTvTTXd3d7qJiNi3b19RV4v9\n+/fHxz72sXT39a9//TTczRO75557Fu1a7ero0aPxX//1X+nulltuSTfr169PNxER//qv/1rUsbCv\nfe1r6aar6yf+iH5CJd+7a3Pq1Kmi71nXXXfdabgbSgwNDcXLXvaydLdnz55081d/9Vfphv+dmZmZ\n2L9/f7p7z3vecxruhhKnTp2Ku+++O919+ctfTjcDAwPpJqLsfVRtOjo6Yvny5enuT//0T9PNyMhI\nuomI2Lt3b1E3H58IAQAAAKphCAEAAACqYQgBAAAAqmEIAQAAAKphCAEAAACqYQgBAAAAqmEIAQAA\nAKphCAEAAACqYQgBAAAAqmEIAQAAAKphCAEAAACqYQgBAAAAqmEIAQAAAKrRtdCLx44dixtuuCH9\nRT/wgQ+km/Xr16ebiIi1a9cWdS972cuKuna0fPnyuOSSS9Ld5s2b001fX1+6iYgYGBhIN9dff33R\ntdrR6tWr41d+5VfS3YYNG9LN2NhYuomIuOqqq4q6D33oQ0VdO1q5cmW89KUvTXclZ/GRRx5JNxER\nH/3oR9PNddddV3StdtQ0TUxNTaW7yy67LN2Ufj+9+uqri7o/+7M/K+raUU9PT5x99tnp7iMf+Ui6\nWbFiRbqJiNi0aVO6ueaaa4qu1Y4OHToU//AP/5DuXvOa16Sbr3zlK+kmIuK3fuu3irpHH320qGtH\nXV1dRe/lP/zhD6eb5cuXp5uIiP7+/nRz7bXXFl2rHfX09MRTn/rUdPeCF7wg3ZT+vjgzM5Nu3vve\n9xZdq11NTEzEbbfdlu7e+MY3ppvOzs50ExFFP7c/+clPzvuaT4QAAAAA1TCEAAAAANUwhAAAAADV\nMIQAAAAA1TCEAAAAANUwhAAAAADVMIQAAAAA1TCEAAAAANUwhAAAAADVMIQAAAAA1TCEAAAAANUw\nhAAAAADVMIQAAAAA1eha6MWOjo5YsWJF+ou+853vTDfd3d3pJiJienq6qKvJkSNH4gtf+EK6O3To\nULrZtm1buomIGBkZSTenTp0qulY7evzxx+P6669Pd8eOHUs34+Pj6SYi4ilPeUpRV5N9+/bFX//1\nX6e7jo78Zl1ypiLKzv3ExETRtdrR1NRU7NmzJ9319/enm9I/1+Hh4aKuJkePHo0bbrgh3c3NzaWb\nkr8vEREzMzPp5uGHHy66Vrvq7OxMN9/97nfTzXe+8510E1H2/bQ24+PjRX++DzzwQLop+T4cEXHP\nPfcUdbU4cuRI/Md//Ee627dvX7rp6+tLNxER27dvTzcHDhwoula76urqiqGhoXT3P//zP+lm165d\n6SYi4oILLkg3hw8fnvc1nwiv3N0kAAALcklEQVQBAAAAqmEIAQAAAKphCAEAAACqYQgBAAAAqmEI\nAQAAAKphCAEAAACqYQgBAAAAqmEIAQAAAKphCAEAAACqYQgBAAAAqmEIAQAAAKphCAEAAACq0bXQ\nix0dHdHf35/+oueee2662bJlS7qJiPj6179e1B04cKCoa0dzc3MxNTWV7jZs2JBubrzxxnTDT3bs\n2LGiv+s1/T1vB9PT07F37950d9ddd52Gu6HEiRMn4vvf/366Gx8fPw13Q6mpqal48MEH0929996b\nblatWpVuIiJGRkaKuprMzs6mm+7u7nQzPDycbiKi6Pt9baampmJsbCzd9fT0pJu+vr50ExHxohe9\nKN2U/JxoV729vXHOOeeku5e85CXp5stf/nK6iSg7w11dC/6avOQ0TRPT09Pp7ujRo+lm7dq16SYi\nYv/+/elmZmZm3td8IgQAAACohiEEAAAAqIYhBAAAAKiGIQQAAACohiEEAAAAqIYhBAAAAKiGIQQA\nAACohiEEAAAAqIYhBAAAAKiGIQQAAACohiEEAAAAqIYhBAAAAKiGIQQAAACoRteCL3Z1xdDQUPqL\nbtmyJd0cPnw43UREbNq0qag7cOBAUdeOVq5cGS996UvT3eOPP55uSp9HX19furnhhhuKrtWOBgYG\n4nnPe166m5ycTDdzc3PpJiJiZmamqKvpOa5atSpe8YpXpLtLLrkk3axfvz7dRET09/enm+uvv77o\nWu1o+fLlsWPHjnTX2dmZblatWpVuIiJarVZR9y//8i9FXTs666yz4u1vf3u6m56eTjf33ntvuomI\neOyxx9LNvn37iq7Vjkrfo77gBS84DXfzxO68886ibmpq6km+k59da9eujTe96U3p7sSJE+lm165d\n6SYioqMj/+/GJd/z29WyZcviGc94RrqbnZ1NN6973evSTUTED3/4w3TTNE3RtdrV4OBgXHHFFemu\n5D3H7bffnm4iIh555JF0c+zYsXlf84kQAAAAoBqGEAAAAKAahhAAAACgGoYQAAAAoBqGEAAAAKAa\nhhAAAACgGoYQAAAAoBqGEAAAAKAahhAAAACgGoYQAAAAoBqGEAAAAKAahhAAAACgGq2maeZ/sdWa\n/8X2d0vTNKNn+iYWw1J+jk3TtM70PSyGpfwMw1lcEpzFJcFZXAKcxSXBWVwCnMX2V8szjKjzOfpE\nCAAAAFANQwgAAABQDUMIAAAAUA1DCAAAAFANQwgAAABQDUMIAAAAUA1DCAAAAFANQwgAAABQDUMI\nAAAAUA1DCAAAAFANQwgAAABQDUMIAAAAUA1DCAAAAFCNroVe7O7ujnXr1qW/6JVXXll8Q1kPPvhg\nUXfjjTc+uTfyM6yvry8uuOCCdLd37950c/DgwXQTEbFy5cp0c/z48aJrcXqUPMOIiKNHjz7Jd8JP\nY8OGDenmscceOw13Qqlly5YVdRMTE0/ynfzsKn1/c84556SbVquVbiIiHn/88XQzNjZWdK2ajI6O\nppvSn28333xzUTc+Pl7UtaPS96jnnXdeuil9jrt27Uo3d955Z9G12tHQ0FC87GUvS3clP3OGhobS\nTUTE97///XRT8tzbWWdnZ9EZufjii9NN0zTpJiLijjvuSDdHjhyZ9zWfCAEAAACqYQgBAAAAqmEI\nAQAAAKphCAEAAACqYQgBAAAAqmEIAQAAAKphCAEAAACqYQgBAAAAqmEIAQAAAKphCAEAAACqYQgB\nAAAAqmEIAQAAAKphCAEAAACq0bXQi3Nzc3HixIn0F92+fXu6GR4eTjcREVu2bCnqbrzxxqKuHS1b\ntiy2bt2a7q666qp089WvfjXdRESMj4+nm4mJiaJrtaOenp4YGRlJdzMzM+mm1Wqlm4iI6enpou7o\n0aNFXTsaGBiI0dHRdHfy5Ml0Mzk5mW4iIvr6+tLN4cOHi67Vjjo6OmL58uXprrOzM910dS34I3pe\nTdMUdTV9T+3t7Y3Nmzenu3PPPTfdrFq1Kt1E/L/3YFmf/exni67VjlqtVtH3q5KfpVdeeWW6iYjY\ntWtXUVfynqhddXZ2xooVK9Ld05/+9HRT8uwjIp75zGemmz179hRdqx319vbGeeedl+5Kfjc5ePBg\nuomIOHDgQLp56KGHiq7Vrjo7O2NwcDDd7dixI93Mzs6mm4iy95sLvYf2iRAAAACgGoYQAAAAoBqG\nEAAAAKAahhAAAACgGoYQAAAAoBqGEAAAAKAahhAAAACgGoYQAAAAoBqGEAAAAKAahhAAAACgGoYQ\nAAAAoBqGEAAAAKAaXQu9eNZZZ8U111yT/qK33357uvn2t7+dbiIixsbGirqatFqt6O3tTXcf/OAH\nT8PdUGJmZiYOHz6c7jo68ltn0zTpJiLi6NGjRV1NJicn48EHH0x3s7Oz6WblypXpJiLie9/7XlFX\ni6Zpip5HSTM3N5duIiLGx8eLupr09PTEyMhIurv11lvTzaFDh9JNRMSPf/zjoq4Wy5Yti+3bt6e7\nrVu3ppu3vvWt6Yb/nZ6enti0aVO6+8EPfpBuPvvZz6abCL9r/CQdHR3R19eX7t797nenm2PHjqWb\niIi9e/cWdTXp7u6O9evXp7udO3emmxtvvDHdnA4+EQIAAABUwxACAAAAVMMQAgAAAFTDEAIAAABU\nwxACAAAAVMMQAgAAAFTDEAIAAABUwxACAAAAVMMQAgAAAFTDEAIAAABUwxACAAAAVMMQAgAAAFTD\nEAIAAABUo9U0zfwvtlrzv7iAP/iDP0g3IyMjJZeK1atXF3VvectbbmmaZrQobjMrV65snvOc56S7\nK664It3cdttt6SYi4sSJE+nmG9/4Rhw6dKhVdME2Mzg42IyO5v+6zs3NpZvu7u50ExFx/Pjxou57\n3/teNWdxZGSkecMb3pDuSv5sJyYm0k1ERF9fX7r553/+59i/f38VZ7Gvr6/ZtGlTuuvp6Uk35557\nbrqJiJieni7qvvKVr1RzFtesWdNcddVV6W7dunXppre3N91ERBw4cCDdfPGLX4wDBw5UcRZL36Nu\n37493fzmb/5myaXiwx/+cFH36KOPVnMWV65c2Vx22WXpbsOGDemm5PxGRCz0u9J8Pv3pT8fevXur\nOIsDAwPNJZdcku6e+cxnppvh4eF0ExHx+c9/Pt3s3r07JiYmqniGEeW/a5Q8k2XLlqWbiIgbb7wx\n3ezduzcmJyef8Dn6RAgAAABQDUMIAAAAUA1DCAAAAFANQwgAAABQDUMIAAAAUA1DCAAAAFANQwgA\nAABQDUMIAAAAUA1DCAAAAFANQwgAAABQDUMIAAAAUA1DCAAAAFCNroVe7O3tjQ0bNqS/6OHDh9PN\nxMREuomIuPfee4u6mszNzRX9+X76059ON3fffXe6iYi45JJL0s3U1FTRtdrR+Ph4fOtb31qUa3V0\nlO2jmzdvfpLvZOk5dOhQfO5zn0t3jzzySLoZGhpKNxERz372s9NNTWdxcnIydu3atSjXuvPOO4u6\nLVu2PMl3svScOnWq6P3D8ePH001X14JvtebV19eXbubm5oquVZONGzemm9tuu63oWqXvbWsyOzsb\n4+Pj6a6kKTU5OZluavq52NHREf39/elubGws3Zw8eTLdRESsWLEi3XR2dhZdq12dPHkyfvCDH6S7\nyy67LN089NBD6SYiYtmyZelmod9rfCIEAAAAqIYhBAAAAKiGIQQAAACohiEEAAAAqIYhBAAAAKiG\nIQQAAACohiEEAAAAqIYhBAAAAKiGIQQAAACohiEEAAAAqIYhBAAAAKiGIQQAAACohiEEAAAAqEar\naZr5X2y1DkTEQ4t3O4tqU9M0w2f6JhbDEn6OnuHS4Dm2P89wafAc259nuDR4ju3PM2x/1TzDiDqf\n44JDCAAAAMBS4n8aAwAAAFTDEAIAAABUwxACAAAAVMMQAgAAAFTDEAIAAABU4/8CDpkDOV+B8O0A\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x576 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-woW1tNhz2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to build basic mlp:\n",
        "def mlp_model3(layers,activation, optimizer,drop_out, num_classes=10):\n",
        "  ''' Build a simple mlp model for multi-class classification;  \n",
        "      Arguments:all the hyperparametes (layers,act,opt, drop_out) to buld in a mlp provided by dictionary of parameters used during hyperparameter\n",
        "      optimization\n",
        "      \n",
        "           '''\n",
        "  from keras.layers import InputLayer\n",
        "  model = Sequential()\n",
        "  for i in range(len(layers)):\n",
        "    if i == 0:\n",
        "        model.add(InputLayer( input_shape=(128,)))\n",
        "        #model.add(Dense(layers[i], activation=activation, input_shape=(32,4,)))\n",
        "        #model.add(Dropout(drop_out))\n",
        "    else:\n",
        "      model.add(Dense(layers[i], activation=activation))\n",
        "      model.add(Dropout(drop_out))\n",
        "  model.add(Dense(num_classes, activation=activation))\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D416Lrt1AU07",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtOfeScFiF_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "029adce3-d581-464c-f32a-1f09da9ec978"
      },
      "source": [
        "(x_train_mae, y_train_mae), (x_test_mae, y_test_mae) = fashion_mnist.load_data()\n",
        "x_train_mae = x_train_mae.reshape(60000, 784)\n",
        "x_test_mae = x_test_mae.reshape(10000, 784)\n",
        "x_train_mae = x_train_mae.astype('float32')\n",
        "x_test_mae = x_test_mae.astype('float32')\n",
        "x_train_mae /= 255\n",
        "x_test_mae /= 255\n",
        "print(x_train_mae.shape, 'train samples')\n",
        "print(x_test_mae.shape[0], 'test samples')\n",
        "y_train_mae = keras.utils.to_categorical(y_train_mae, 10)\n",
        "y_label = keras.utils.to_categorical(y_test_mae,10)\n",
        "#y_train.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784) train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJZwVDQjjEve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_3 = x_train_mae.reshape(60000, 28,28,1)\n",
        "x_test_3 = x_test_mae.reshape(10000,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2eFMrrciujX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_train_image = encoder_train.predict(x_train_3)\n",
        "encoder_test_image = encoder_train.predict(x_test_3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAV6iivhdcMN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXRPj4rUJm7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9129
        },
        "outputId": "d3678d08-c2bc-45d8-d62d-f07b92c13dd4"
      },
      "source": [
        "model3 = KerasClassifier(build_fn=mlp_model3, epochs=30, batch_size=256, verbose=1)\n",
        "print(y_train.shape)\n",
        "print(x_train_3.shape)\n",
        "\n",
        "parameter = {'layers':[[512,512],[512,512,512]],'activation': [ 'relu',],\n",
        "             'optimizer': [ 'Adam' ],\n",
        "             'drop_out': [ 0.1]}\n",
        "classifier3 = GridSearchCV(estimator=model3, param_grid=parameter,verbose = 1)\n",
        "search_result3 = classifier3.fit(encoder_train_image.reshape(60000,128), y_train_mae)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "(60000, 28, 28, 1)\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_61 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 71,178\n",
            "Trainable params: 71,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "40000/40000 [==============================] - 2s 57us/step - loss: 2.8813 - acc: 0.4850\n",
            "Epoch 2/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.9197 - acc: 0.3339\n",
            "Epoch 3/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.7601 - acc: 0.4440\n",
            "Epoch 4/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.9479 - acc: 0.2461\n",
            "Epoch 5/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.6500 - acc: 0.5283\n",
            "Epoch 6/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.9540 - acc: 0.2751\n",
            "Epoch 7/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 3.1235 - acc: 0.1441\n",
            "Epoch 8/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.9365 - acc: 0.2575\n",
            "Epoch 9/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.7265 - acc: 0.4703\n",
            "Epoch 10/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.6742 - acc: 0.4901\n",
            "Epoch 11/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 3.0011 - acc: 0.1675\n",
            "Epoch 12/30\n",
            "40000/40000 [==============================] - 1s 15us/step - loss: 2.7684 - acc: 0.4275\n",
            "Epoch 13/30\n",
            "40000/40000 [==============================] - 1s 15us/step - loss: 2.9601 - acc: 0.2853\n",
            "Epoch 14/30\n",
            "40000/40000 [==============================] - 1s 15us/step - loss: 2.8490 - acc: 0.3599\n",
            "Epoch 15/30\n",
            "40000/40000 [==============================] - 1s 15us/step - loss: 2.7952 - acc: 0.4027\n",
            "Epoch 16/30\n",
            "40000/40000 [==============================] - 1s 15us/step - loss: 2.6743 - acc: 0.5165\n",
            "Epoch 17/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.6257 - acc: 0.5445\n",
            "Epoch 18/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.6142 - acc: 0.5452\n",
            "Epoch 19/30\n",
            "40000/40000 [==============================] - 1s 15us/step - loss: 2.6223 - acc: 0.5559\n",
            "Epoch 20/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.5982 - acc: 0.5673\n",
            "Epoch 21/30\n",
            "40000/40000 [==============================] - 1s 15us/step - loss: 2.8331 - acc: 0.3077\n",
            "Epoch 22/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.6899 - acc: 0.4580\n",
            "Epoch 23/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.5971 - acc: 0.5539\n",
            "Epoch 24/30\n",
            "40000/40000 [==============================] - 1s 15us/step - loss: 2.5806 - acc: 0.5809\n",
            "Epoch 25/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.5689 - acc: 0.5839\n",
            "Epoch 26/30\n",
            "40000/40000 [==============================] - 1s 15us/step - loss: 2.5727 - acc: 0.5455\n",
            "Epoch 27/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 2.6920 - acc: 0.4919\n",
            "Epoch 28/30\n",
            "40000/40000 [==============================] - 1s 15us/step - loss: 2.5572 - acc: 0.5802\n",
            "Epoch 29/30\n",
            "40000/40000 [==============================] - 1s 15us/step - loss: 2.5416 - acc: 0.5967\n",
            "Epoch 30/30\n",
            "40000/40000 [==============================] - 1s 13us/step - loss: 2.5653 - acc: 0.5172\n",
            "20000/20000 [==============================] - 1s 42us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_63 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 71,178\n",
            "Trainable params: 71,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "40000/40000 [==============================] - 2s 59us/step - loss: 5.9359 - acc: 0.3354\n",
            "Epoch 2/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5402 - acc: 0.4234\n",
            "Epoch 3/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5728 - acc: 0.4136\n",
            "Epoch 4/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.6745 - acc: 0.2990\n",
            "Epoch 5/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5544 - acc: 0.4177\n",
            "Epoch 6/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4873 - acc: 0.4555\n",
            "Epoch 7/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.8377 - acc: 0.1913\n",
            "Epoch 8/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5769 - acc: 0.3921\n",
            "Epoch 9/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5306 - acc: 0.3989\n",
            "Epoch 10/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5512 - acc: 0.3854\n",
            "Epoch 11/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.8346 - acc: 0.1812\n",
            "Epoch 12/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5980 - acc: 0.3781\n",
            "Epoch 13/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5693 - acc: 0.4044\n",
            "Epoch 14/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5370 - acc: 0.4263\n",
            "Epoch 15/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4884 - acc: 0.4455\n",
            "Epoch 16/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5237 - acc: 0.4120\n",
            "Epoch 17/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4968 - acc: 0.4329\n",
            "Epoch 18/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5417 - acc: 0.4075\n",
            "Epoch 19/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5185 - acc: 0.4158\n",
            "Epoch 20/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4320 - acc: 0.4582\n",
            "Epoch 21/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4976 - acc: 0.4297\n",
            "Epoch 22/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.7465 - acc: 0.2190\n",
            "Epoch 23/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5646 - acc: 0.3654\n",
            "Epoch 24/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5339 - acc: 0.3923\n",
            "Epoch 25/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5038 - acc: 0.4413\n",
            "Epoch 26/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4756 - acc: 0.4522\n",
            "Epoch 27/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5193 - acc: 0.4224\n",
            "Epoch 28/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.6003 - acc: 0.3249\n",
            "Epoch 29/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5771 - acc: 0.3933\n",
            "Epoch 30/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4738 - acc: 0.4548\n",
            "20000/20000 [==============================] - 1s 42us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_65 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 71,178\n",
            "Trainable params: 71,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "40000/40000 [==============================] - 2s 60us/step - loss: 6.4699 - acc: 0.3604\n",
            "Epoch 2/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4970 - acc: 0.4562\n",
            "Epoch 3/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4290 - acc: 0.5038\n",
            "Epoch 4/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.3957 - acc: 0.5180\n",
            "Epoch 5/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4942 - acc: 0.4444\n",
            "Epoch 6/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4725 - acc: 0.4394\n",
            "Epoch 7/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.3526 - acc: 0.5289\n",
            "Epoch 8/30\n",
            "40000/40000 [==============================] - 1s 13us/step - loss: 5.3532 - acc: 0.5351\n",
            "Epoch 9/30\n",
            "40000/40000 [==============================] - 1s 13us/step - loss: 5.4657 - acc: 0.4317\n",
            "Epoch 10/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.3600 - acc: 0.5174\n",
            "Epoch 11/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.6788 - acc: 0.2818\n",
            "Epoch 12/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4191 - acc: 0.4860\n",
            "Epoch 13/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4651 - acc: 0.4446\n",
            "Epoch 14/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.5109 - acc: 0.4182\n",
            "Epoch 15/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4692 - acc: 0.4567\n",
            "Epoch 16/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.3838 - acc: 0.5071\n",
            "Epoch 17/30\n",
            "40000/40000 [==============================] - 1s 13us/step - loss: 5.3630 - acc: 0.5082\n",
            "Epoch 18/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4911 - acc: 0.4001\n",
            "Epoch 19/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.3519 - acc: 0.5039\n",
            "Epoch 20/30\n",
            "40000/40000 [==============================] - 1s 15us/step - loss: 5.3326 - acc: 0.5222\n",
            "Epoch 21/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.3645 - acc: 0.4891\n",
            "Epoch 22/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4550 - acc: 0.4405\n",
            "Epoch 23/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4842 - acc: 0.4060\n",
            "Epoch 24/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.3196 - acc: 0.5218\n",
            "Epoch 25/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.3214 - acc: 0.5288\n",
            "Epoch 26/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.3904 - acc: 0.4705\n",
            "Epoch 27/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.4530 - acc: 0.4434\n",
            "Epoch 28/30\n",
            "40000/40000 [==============================] - 1s 13us/step - loss: 5.5046 - acc: 0.3706\n",
            "Epoch 29/30\n",
            "40000/40000 [==============================] - 1s 14us/step - loss: 5.3546 - acc: 0.5215\n",
            "Epoch 30/30\n",
            "40000/40000 [==============================] - 1s 13us/step - loss: 5.3360 - acc: 0.5333\n",
            "20000/20000 [==============================] - 1s 42us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_67 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 333,834\n",
            "Trainable params: 333,834\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "40000/40000 [==============================] - 3s 65us/step - loss: 3.6438 - acc: 0.4448\n",
            "Epoch 2/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.6498 - acc: 0.5559\n",
            "Epoch 3/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.8504 - acc: 0.4270\n",
            "Epoch 4/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.7133 - acc: 0.5038\n",
            "Epoch 5/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.6175 - acc: 0.5454\n",
            "Epoch 6/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.4477 - acc: 0.6270\n",
            "Epoch 7/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.4036 - acc: 0.6263\n",
            "Epoch 8/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.3774 - acc: 0.6507\n",
            "Epoch 9/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.3852 - acc: 0.6250\n",
            "Epoch 10/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.5847 - acc: 0.4980\n",
            "Epoch 11/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.4273 - acc: 0.6195\n",
            "Epoch 12/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.4017 - acc: 0.6142\n",
            "Epoch 13/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.3249 - acc: 0.6621\n",
            "Epoch 14/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.3823 - acc: 0.6205\n",
            "Epoch 15/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.4362 - acc: 0.6123\n",
            "Epoch 16/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.4738 - acc: 0.5909\n",
            "Epoch 17/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.7551 - acc: 0.4823\n",
            "Epoch 18/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.7204 - acc: 0.4128\n",
            "Epoch 19/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.5093 - acc: 0.5795\n",
            "Epoch 20/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.9665 - acc: 0.3259\n",
            "Epoch 21/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.7413 - acc: 0.4209\n",
            "Epoch 22/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.7034 - acc: 0.4784\n",
            "Epoch 23/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.5788 - acc: 0.4996\n",
            "Epoch 24/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.5278 - acc: 0.5638\n",
            "Epoch 25/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.8152 - acc: 0.3506\n",
            "Epoch 26/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.5751 - acc: 0.5485\n",
            "Epoch 27/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.4854 - acc: 0.6111\n",
            "Epoch 28/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.4639 - acc: 0.6179\n",
            "Epoch 29/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.4199 - acc: 0.6194\n",
            "Epoch 30/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.5246 - acc: 0.5755\n",
            "20000/20000 [==============================] - 1s 45us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_70 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 333,834\n",
            "Trainable params: 333,834\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "40000/40000 [==============================] - 3s 67us/step - loss: 4.2251 - acc: 0.5119\n",
            "Epoch 2/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 3.9502 - acc: 0.5828\n",
            "Epoch 3/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 4.0722 - acc: 0.5249\n",
            "Epoch 4/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 3.9890 - acc: 0.5529\n",
            "Epoch 5/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 3.9778 - acc: 0.5075\n",
            "Epoch 6/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 3.8972 - acc: 0.6161\n",
            "Epoch 7/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 4.0219 - acc: 0.5314\n",
            "Epoch 8/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 4.0409 - acc: 0.5235\n",
            "Epoch 9/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 3.8772 - acc: 0.6216\n",
            "Epoch 10/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 3.8397 - acc: 0.6095\n",
            "Epoch 11/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 3.7660 - acc: 0.6542\n",
            "Epoch 12/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 3.9315 - acc: 0.5172\n",
            "Epoch 13/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 3.9401 - acc: 0.5458\n",
            "Epoch 14/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 3.9193 - acc: 0.5660\n",
            "Epoch 15/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 3.9237 - acc: 0.5156\n",
            "Epoch 16/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 4.7604 - acc: 0.4276\n",
            "Epoch 17/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 5.7049 - acc: 0.2380\n",
            "Epoch 18/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 5.2377 - acc: 0.4701\n",
            "Epoch 19/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 5.3840 - acc: 0.4982\n",
            "Epoch 20/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 5.4055 - acc: 0.4779\n",
            "Epoch 21/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 5.4848 - acc: 0.3975\n",
            "Epoch 22/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 5.5587 - acc: 0.3992\n",
            "Epoch 23/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 5.5318 - acc: 0.3733\n",
            "Epoch 24/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 5.4033 - acc: 0.5248\n",
            "Epoch 25/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 5.0774 - acc: 0.5492\n",
            "Epoch 26/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 3.9190 - acc: 0.6275\n",
            "Epoch 27/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 3.9290 - acc: 0.6011\n",
            "Epoch 28/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 4.0803 - acc: 0.4626\n",
            "Epoch 29/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 3.8927 - acc: 0.5948\n",
            "Epoch 30/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 3.9135 - acc: 0.5381\n",
            "20000/20000 [==============================] - 1s 46us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_73 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 333,834\n",
            "Trainable params: 333,834\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "40000/40000 [==============================] - 3s 67us/step - loss: 3.0731 - acc: 0.3875\n",
            "Epoch 2/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.6702 - acc: 0.5210\n",
            "Epoch 3/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.4853 - acc: 0.6129\n",
            "Epoch 4/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.4350 - acc: 0.6235\n",
            "Epoch 5/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.4093 - acc: 0.6264\n",
            "Epoch 6/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.4415 - acc: 0.6126\n",
            "Epoch 7/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.4200 - acc: 0.6343\n",
            "Epoch 8/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.4015 - acc: 0.6263\n",
            "Epoch 9/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.4130 - acc: 0.6229\n",
            "Epoch 10/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.5418 - acc: 0.5698\n",
            "Epoch 11/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.3904 - acc: 0.6188\n",
            "Epoch 12/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.3557 - acc: 0.6424\n",
            "Epoch 13/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.3576 - acc: 0.6501\n",
            "Epoch 14/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.3717 - acc: 0.6539\n",
            "Epoch 15/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.3155 - acc: 0.6713\n",
            "Epoch 16/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.5494 - acc: 0.5610\n",
            "Epoch 17/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.9627 - acc: 0.4151\n",
            "Epoch 18/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.5389 - acc: 0.5624\n",
            "Epoch 19/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.3994 - acc: 0.6324\n",
            "Epoch 20/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.5397 - acc: 0.5314\n",
            "Epoch 21/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.4560 - acc: 0.5996\n",
            "Epoch 22/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.3956 - acc: 0.6239\n",
            "Epoch 23/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.3615 - acc: 0.6417\n",
            "Epoch 24/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.3380 - acc: 0.6620\n",
            "Epoch 25/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.3513 - acc: 0.6408\n",
            "Epoch 26/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.3537 - acc: 0.6216\n",
            "Epoch 27/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.4558 - acc: 0.5854\n",
            "Epoch 28/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.4260 - acc: 0.5725\n",
            "Epoch 29/30\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: 2.7040 - acc: 0.4598\n",
            "Epoch 30/30\n",
            "40000/40000 [==============================] - 1s 16us/step - loss: 2.6545 - acc: 0.5390\n",
            "20000/20000 [==============================] - 1s 49us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_76 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_53 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 71,178\n",
            "Trainable params: 71,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 2.8553 - acc: 0.4842\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.8246 - acc: 0.3922\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.7419 - acc: 0.4188\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.6953 - acc: 0.4262\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.6571 - acc: 0.4600\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.4804 - acc: 0.6432\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.7502 - acc: 0.3782\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.5144 - acc: 0.5917\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.8541 - acc: 0.2811\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.5215 - acc: 0.5758\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.5612 - acc: 0.5937\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.5925 - acc: 0.4872\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.5379 - acc: 0.6052\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.4554 - acc: 0.6167\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 2.5531 - acc: 0.5587\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.4203 - acc: 0.6665\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 2.3974 - acc: 0.6773\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.6368 - acc: 0.4566\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.4603 - acc: 0.6159\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.4012 - acc: 0.6329\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.3895 - acc: 0.6364\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.4242 - acc: 0.6217\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.4058 - acc: 0.6131\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.3584 - acc: 0.6962\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.5047 - acc: 0.5590\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.4993 - acc: 0.5381\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.3883 - acc: 0.6471\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.3635 - acc: 0.6693\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 2.3630 - acc: 0.6704\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 2.3332 - acc: 0.6733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBVGeuLPKngz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e0dd4992-40ac-458b-91a1-3aef41d86695"
      },
      "source": [
        "print(\"Best Accuracy: %f using %s\" % (search_result3.best_score_, search_result3.best_params_))\n",
        "best_estimator_mlp_ae = classifier3.best_estimator_\n",
        "y_pred = best_estimator_mlp_ae.predict(encoder_test_image.reshape(10000,128))\n",
        "accuracy = (accuracy_score(y_test_mae,y_pred)*100)\n",
        "#print(accuracy)\n",
        "\n",
        "Result2 = {'ae_mle_acc':[],'ae_rf_accu':[]}\n",
        "Result2.update(ae_mle_acc= accuracy)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Accuracy: 0.527683 using {'activation': 'relu', 'drop_out': 0.1, 'layers': [512, 512], 'optimizer': 'Adam'}\n",
            "10000/10000 [==============================] - 0s 6us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-7gxq1VvS7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "41b52f9d-f606-4097-9b39-620a41d1f694"
      },
      "source": [
        "model_rfc = RandomForestClassifier(n_estimators=64, n_jobs=-1)\n",
        "model_rfc.fit(encoder_train_image.reshape(60000,128), y_train_mae)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=64, n_jobs=-1,\n",
              "                       oob_score=False, random_state=None, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0lRRnDpwFgt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b728186-b044-4e5d-e432-29a082d46694"
      },
      "source": [
        "rfc_accuracy_ae = model_rfc.score(encoder_test_image.reshape(10000,128),y_label)*100\n",
        "print(rfc_accuracy_ae)\n",
        "Result2.update(ae_rf_accu=rfc_accuracy_ae)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76.99000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2NWAExiajCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "19201204-bba6-4396-849d-ac09a1554a2a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "plt.bar(range(len(Result2)), list(Result2.values()), align='center')\n",
        "plt.xticks(range(len(Result2)), list(Result2.keys()))\n",
        "plt.title('performance in th latent vector')\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEJCAYAAACE39xMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNhOUQwh3ZUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "9900ed4f-4d08-4cfc-a58a-fc39d8728824"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(Result2)\n",
        "print(Result1)\n",
        "\n",
        "#D = {u'Label1':26, u'Label2': 17, u'Label3':30}\n",
        "\n",
        "\n",
        "plt.bar(range(len(Result1)), list(Result1.values()), align='center')\n",
        "plt.xticks(range(len(Result1)), list(Result1.keys()))\n",
        "plt.title('performance in the originalDataset')\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ae_mle_acc': 67.93, 'ae_rf_accu': 76.99000000000001}\n",
            "{'mlp_accu': 93.71000000000001, 'rf_accu': 90.06, 'cnn_acu': 98.97}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEJCAYAAACaFuz/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzvmuG0nqnEEvSZ0z6CWpcwa9JHXu/wM0SiyZJ1tqlgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oUFef-mxeiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}