{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_1_Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girisiman/Deep_Learning_Tasks/blob/master/GAN_1_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnVxQ9aZYpKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prerequisites\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rWGWPLYYsrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "f399b727-3233-4c30-cfac-44b27844c91f"
      },
      "source": [
        "bs = 100\n",
        "\n",
        "# MNIST Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 27476936.06it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 465822.12it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 147819.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7232656.74it/s]                           \n",
            "8192it [00:00, 185282.64it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v4iD4v9Y1lq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "6567f0b5-0d70-4b2e-caed-85092133e14b"
      },
      "source": [
        "train_dataset\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./mnist_data/\n",
              "    Split: Train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCQ9oVZ-A3a5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "n_colours = 1\n",
        "z_size = 100\n",
        "G_h_size = 28\n",
        "D_h_size = 28\n",
        "image_size = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJF2pHyxY8ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transf\n",
        "import torchvision.models as models\n",
        "import torchvision.utils as vutils\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fJ8PVdaZ4_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 28\n",
        "G_h_size = 28\n",
        "class DCGAN_G(torch.nn.Module):\n",
        "\tdef __init__(self):\n",
        "    \n",
        "    #self.image_size = image_size\n",
        "    #self.G_h_size = G_h_size\n",
        "    #self.z_size = z_size\n",
        "    \n",
        "\t\tsuper(DCGAN_G, self).__init__()\n",
        "\t\tmain = torch.nn.Sequential()\n",
        "\n",
        "\t\t# We need to know how many layers we will use at the beginning\n",
        "\t\tmult = image_size // 8\n",
        "\n",
        "\t\t### Start block\n",
        "\t\t# Z_size random numbers\n",
        "\t\tmain.add_module('Start-ConvTranspose2d', torch.nn.ConvTranspose2d(z_size, G_h_size * mult, kernel_size=2, stride=1, padding=0, bias=False))\n",
        "\t\tif F.selu:\n",
        "\t\t\tmain.add_module('Start-SELU', torch.nn.SELU(inplace=True))\n",
        "\t\telse:\n",
        "\t\t\tmain.add_module('Start-BatchNorm2d', torch.nn.BatchNorm2d(G_h_size * mult))\n",
        "\t\t\tmain.add_module('Start-ReLU', torch.nn.ReLU())\n",
        "\t\t# Size = (G_h_size * mult) x 4 x 4\n",
        "\n",
        "\t\t### Middle block (Done until we reach ? x image_size/2 x image_size/2)\n",
        "\t\ti = 1\n",
        "\t\twhile mult > 1:\n",
        "\t\t\tmain.add_module('Middle-ConvTranspose2d [%d]' % i, torch.nn.ConvTranspose2d(G_h_size * mult, G_h_size * (mult//2), kernel_size=2, stride=1, padding=1, bias=False))\n",
        "\t\t\tif torch.nn.SELU:\n",
        "\t\t\t\tmain.add_module('Middle-SELU [%d]' % i, torch.nn.SELU(inplace=True))\n",
        "\t\t\telse:\n",
        "\t\t\t\tmain.add_module('Middle-BatchNorm2d [%d]' % i, torch.nn.BatchNorm2d(G_h_size * (mult//2)))\n",
        "\t\t\t\tmain.add_module('Middle-ReLU [%d]' % i, torch.nn.ReLU())\n",
        "\t\t\t# Size = (G_h_size * (mult/(2*i))) x 8 x 8\n",
        "\t\t\tmult = mult // 2\n",
        "\t\t\ti += 1\n",
        "\n",
        "\t\t### End block\n",
        "\t\t# Size = G_h_size x image_size/2 x image_size/2\n",
        "\t\tmain.add_module('End-ConvTranspose2d', torch.nn.ConvTranspose2d(G_h_size, 1, kernel_size=2, stride=1, padding=1, bias=False))\n",
        "\t\tmain.add_module('End-Tanh', torch.nn.Tanh())\n",
        "\t\t# Size = n_colors x image_size x image_size\n",
        "\t\tself.main = main\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\toutput = self.main(input)\n",
        "\t\treturn output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJet54_tdVtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_size = 100\n",
        "g = DCGAN_G()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv9ufJ6-ggIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "10940bb3-ce27-48ef-dc9c-fd1107d3b0b7"
      },
      "source": [
        "g"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DCGAN_G(\n",
              "  (main): Sequential(\n",
              "    (Start-ConvTranspose2d): ConvTranspose2d(100, 84, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
              "    (Start-SELU): SELU(inplace)\n",
              "    (Middle-ConvTranspose2d [1]): ConvTranspose2d(84, 28, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (Middle-SELU [1]): SELU(inplace)\n",
              "    (End-ConvTranspose2d): ConvTranspose2d(28, 1, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (End-Tanh): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46l68sTEinEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_h_size = 28\n",
        "class DCGAN_D(torch.nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(DCGAN_D, self).__init__()\n",
        "\t\tmain = torch.nn.Sequential()\n",
        "\n",
        "\t\t### Start block\n",
        "\t\t# Size = n_colors x image_size x image_size\n",
        "\t\tmain.add_module('Start-Conv2d', torch.nn.Conv2d(1, D_h_size, kernel_size=2, stride=1, padding=1, bias=False))\n",
        "\t\tif torch.nn.SELU:\n",
        "\t\t\tmain.add_module('Start-SELU', torch.nn.SELU(inplace=True))\n",
        "\t\telse:\n",
        "\t\t\tmain.add_module('Start-LeakyReLU', torch.nn.LeakyReLU(0.2, inplace=True))\n",
        "\t\timage_size_new = image_size // 2\n",
        "\t\t# Size = D_h_size x image_size/2 x image_size/2\n",
        "\n",
        "\t\t### Middle block (Done until we reach ? x 4 x 4)\n",
        "\t\tmult = 1\n",
        "\t\ti = 0\n",
        "\t\twhile image_size_new > 4:\n",
        "\t\t\tmain.add_module('Middle-Conv2d [%d]' % i, torch.nn.Conv2d(D_h_size * mult, D_h_size * (2*mult), kernel_size=2, stride=1, padding=1, bias=False))\n",
        "\t\t\tif torch.nn.SELU:\n",
        "\t\t\t\tmain.add_module('Middle-SELU [%d]' % i, torch.nn.SELU(inplace=True))\n",
        "\t\t\telse:\n",
        "\t\t\t\tmain.add_module('Middle-BatchNorm2d [%d]' % i, torch.nn.BatchNorm2d(D_h_size * (2*mult)))\n",
        "\t\t\t\tmain.add_module('Middle-LeakyReLU [%d]' % i, torch.nn.LeakyReLU(0.2, inplace=True))\n",
        "\t\t\t# Size = (D_h_size*(2*i)) x image_size/(2*i) x image_size/(2*i)\n",
        "\t\t\timage_size_new = image_size_new // 2\n",
        "\t\t\tmult *= 2\n",
        "\t\t\ti += 1\n",
        "\n",
        "\t\t### End block\n",
        "\t\t# Size = (D_h_size * mult) x 4 x 4\n",
        "\t\tmain.add_module('End-Conv2d', torch.nn.Conv2d(D_h_size * mult, 1, kernel_size=2, stride=1, padding=0, bias=False))\n",
        "\t\tmain.add_module('End-Sigmoid', torch.nn.Sigmoid())\n",
        "\t\t# Size = 1 x 1 x 1 (Is a real cat or not?)\n",
        "\t\tself.main = main\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\tif isinstance(input.data, torch.cuda.FloatTensor) and param.n_gpu > 1:\n",
        "\t\t\toutput = torch.nn.parallel.data_parallel(self.main, input, range(param.n_gpu))\n",
        "\t\telse:\n",
        "\t\t\toutput = self.main(input)\n",
        "\t\t# Convert from 1 x 1 x 1 to 1 so that we can compare to given label (cat or not?)\n",
        "\t\treturn output.view(-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js43HITOnFO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = DCGAN_D()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvZdctaPnkB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "6439660a-51fb-40c3-c423-ba15ca21a7ae"
      },
      "source": [
        "d"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DCGAN_D(\n",
              "  (main): Sequential(\n",
              "    (Start-Conv2d): Conv2d(1, 28, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (Start-SELU): SELU(inplace)\n",
              "    (Middle-Conv2d [0]): Conv2d(28, 56, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (Middle-SELU [0]): SELU(inplace)\n",
              "    (Middle-Conv2d [1]): Conv2d(56, 112, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (Middle-SELU [1]): SELU(inplace)\n",
              "    (End-Conv2d): Conv2d(112, 1, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
              "    (End-Sigmoid): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7gkJaSPnomb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "\tclassname = m.__class__.__name__\n",
        "\tif classname.find('Conv') != -1:\n",
        "\t\tm.weight.data.normal_(0.0, 0.02)\n",
        "\telif classname.find('BatchNorm') != -1:\n",
        "\t\t# Estimated variance, must be around 1\n",
        "\t\tm.weight.data.normal_(1.0, 0.02)\n",
        "\t\t# Estimated mean, must be around 0\n",
        "\t\tm.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b4_HFb7XHZi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "1c8778e5-5156-4da7-f1f7-ce7890c25d7c"
      },
      "source": [
        "g.apply(weights_init)\n",
        "\n"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DCGAN_G(\n",
              "  (main): Sequential(\n",
              "    (Start-ConvTranspose2d): ConvTranspose2d(100, 84, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
              "    (Start-SELU): SELU(inplace)\n",
              "    (Middle-ConvTranspose2d [1]): ConvTranspose2d(84, 28, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (Middle-SELU [1]): SELU(inplace)\n",
              "    (End-ConvTranspose2d): ConvTranspose2d(28, 1, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (End-Tanh): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBuEcu-yXR2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "ea1cdb2a-e182-477a-b5dc-45d7491580a1"
      },
      "source": [
        "d.apply(weights_init)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DCGAN_D(\n",
              "  (main): Sequential(\n",
              "    (Start-Conv2d): Conv2d(1, 28, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (Start-SELU): SELU(inplace)\n",
              "    (Middle-Conv2d [0]): Conv2d(28, 56, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (Middle-SELU [0]): SELU(inplace)\n",
              "    (Middle-Conv2d [1]): Conv2d(56, 112, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (Middle-SELU [1]): SELU(inplace)\n",
              "    (End-Conv2d): Conv2d(112, 1, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
              "    (End-Sigmoid): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-BjF5OEXWZd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c7664fc8-27b3-4b51-c2c7-f684888f8e41"
      },
      "source": [
        "# Load existing models\n",
        "if G_load != '':\n",
        "\tg.load_state_dict(torch.load(G_load))\n",
        "if D_load != '':\n",
        "\td.load_state_dict(torch.load(D_load))\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-a2ce98ec3315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mG_load\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mD_load\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'G_load' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hKcQ3b1XdnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnqrhP6JX6au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mb_size = 64\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "trainData = torchvision.datasets.MNIST('./data/', download=True, transform=transform, train=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(trainData, shuffle=True, batch_size=mb_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fUCh-Uvvqv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "48085878-0f01-452b-ac95-77750c2e4734"
      },
      "source": [
        "import random\n",
        "seed = random.randint(1, 10000)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7ef969b8b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNB_gW6pwMuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 28\n",
        "## Transforming images\n",
        "trans = transf.Compose([\n",
        "\ttransf.Resize((image_size)),\n",
        "\t# This makes it into [0,1]\n",
        "\ttransf.ToTensor(),\n",
        "\t# This makes it into [-1,1] so tanh will work properly\n",
        "\ttransf.Normalize(mean = [0.5], std = [0.5])\n",
        "])\n",
        "\n",
        "## Importing dataset\n",
        "data = dset.MNIST(root='./mnist_data/', train=True, transform=trans, download=True)\n",
        "\n",
        "# Loading data in batch\n",
        "dataset = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpwi-Ku6wvMX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d7d81ff9-59a2-42a5-f0ea-a8eeaddb51cb"
      },
      "source": [
        "data"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./mnist_data/\n",
              "    Split: Train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtPfpfzFxyb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Based on DCGAN paper, they found using betas[0]=.50 better.\n",
        "# betas[0] represent is the weight given to the previous mean of the gradient\n",
        "# betas[1] is the weight given to the previous variance of the gradient\n",
        "lr_D = 0.00005\n",
        "lr_G = 0.0002\n",
        "beta1 = 0.5\n",
        "optimizerd = torch.optim.Adam(d.parameters(), lr=lr_D, betas=(beta1, 0.999))\n",
        "optimizerg = torch.optim.Adam(g.parameters(), lr=lr_G, betas=(beta1, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd8PB4zVytsO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "cb4b2bcd-99a2-4bd7-8119-15c90cf314c2"
      },
      "source": [
        "\n",
        "# Soon to be variables\n",
        "x = torch.FloatTensor(batch_size, n_colours, image_size, image_size)\n",
        "y = torch.FloatTensor(batch_size)\n",
        "z = torch.FloatTensor(batch_size, z_size, 1, 1)\n",
        "# This is to see during training, size and values won't change\n",
        "z_test = torch.FloatTensor(batch_size, z_size, 1, 1).normal_(0, 1)\n",
        "# Now Variables\n",
        "x = Variable(x)\n",
        "y = Variable(y)\n",
        "z = Variable(z)\n",
        "z_test = Variable(z_test)\n",
        "\n",
        "for epoch in range(20):\n",
        "  err_d_rum = 0.0\n",
        "  err_g_run = 0.0\n",
        "  for i, data_batch in enumerate(dataset,0):\n",
        "\t\t########################\n",
        "\t\t# (1) Update D network #\n",
        "\t\t########################\n",
        "    for p in d.parameters():\n",
        "      p.requires_grad = True\n",
        "\n",
        "\t\t# Train with real data\n",
        "    d.zero_grad()\n",
        "\t\t# We can ignore labels since they are all cats!\n",
        "    images, labels = data_batch\n",
        "    #print(images)\n",
        "\t\t# Mostly necessary for the last one because if N might not be a multiple of batch_size\n",
        "    current_batch_size = images.size(0)\n",
        "    print(current_batch_size)\n",
        "\t\t# Transfer batch of images to x\n",
        "    x.data.resize_as_(images).copy_(images)\n",
        "    print(x.size())\n",
        "\t\t# y is now a vector of size current_batch_size filled with 1\n",
        "    y.data.resize_(current_batch_size).fill_(1)\n",
        "    print(y.size())\n",
        "    y_pred = d(images)\n",
        "    print(y_pred.size())\n",
        "    errD_real = criterion(y_pred, y)\n",
        "    errD_real.backward()\n",
        "\t\t# Var has data and gradient element, we keep the mean of the data element\n",
        "    D_real = y_pred.data.mean()\n",
        "\n",
        "\t\t# Train with fake data\n",
        "    z.data.resize_(current_batch_size, z_size, 1, 1).normal_(0, 1)\n",
        "    x_fake = g(z)\n",
        "    y.data.resize_(current_batch_size).fill_(0)\n",
        "\t\t# Detach y_pred from the neural network G and put it inside D\n",
        "    y_pred_fake = d(x_fake.detach())\n",
        "    errD_fake = criterion(y_pred_fake, y)\n",
        "    errD_fake.backward()\n",
        "    D_fake = y_pred_fake.data.mean()\n",
        "    errD = errD_real + errD_fake\n",
        "    optimizerd.step()\n",
        "    # (2) Update G network #\n",
        "\t\t########################\n",
        "\n",
        "\t\t# Make it a tiny bit faster\n",
        "    for p in d.parameters():\n",
        "      p.requires_grad = False\n",
        "    g.zero_grad()\n",
        "\t\t# Generator wants to fool discriminator so it wants to minimize loss of discriminator assuming label is True\n",
        "    y.data.resize_(current_batch_size).fill_(1)\n",
        "    y_pred_fake = d(x_fake)\n",
        "    errG = criterion(y_pred_fake, y)\n",
        "    errG.backward(retain_graph=True)\n",
        "    D_G = y_pred_fake.data.mean()\n",
        "    optimizerg.step()\n",
        "    current_step = i + epoch*len(dataset)\n",
        "    err_d_run += err_d.item()\n",
        "    err_g_run += err_g.item()\n",
        "print('Epoch:{},   G_loss:{},    D_loss:{}'.format(epoch, err_g_run/(i+1), err_d_run/(i+1)))\n",
        "samples = G(z).detach()\n",
        "samples = samples.view(samples.size(0), 1, 28, 28).cpu()\n",
        "imshow(samples)\n",
        "    "
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28\n",
            "torch.Size([28, 1, 28, 28])\n",
            "torch.Size([28])\n",
            "torch.Size([25200])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:512: UserWarning: Using a target size (torch.Size([28])) that is different to the input size (torch.Size([25200])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-b12f74eeb814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0merrD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0merrD_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;31m# Var has data and gradient element, we keep the mean of the data element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m         raise ValueError(\"Target and input must have the same number of elements. target nelement ({}) \"\n\u001b[0;32m-> 2106\u001b[0;31m                          \"!= input nelement ({})\".format(target.numel(), input.numel()))\n\u001b[0m\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target and input must have the same number of elements. target nelement (28) != input nelement (25200)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwQVokrLByVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.FloatTensor(batch_size, n_colours, image_size, image_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTphn8-nBzCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1635
        },
        "outputId": "40bc38bf-5c49-4f3d-e60a-515e171464d7"
      },
      "source": [
        "x"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,         nan,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          ...,\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.1491e-43,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00, -3.3125e+26,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00, -9.4780e+26,  1.3566e-21,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          ...,\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          ...,\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00, -3.2768e+04,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            4.5890e+27,  1.6142e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.9923e+08,\n",
              "            5.7453e-44, -2.2518e+15],\n",
              "          [ 9.0754e-41,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00, -9.0072e+15],\n",
              "          ...,\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          ...,\n",
              "          [ 0.0000e+00,  0.0000e+00,  3.9443e-31,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00, -4.1207e+34,  ..., -1.2030e+38,\n",
              "            2.1832e-41,  0.0000e+00],\n",
              "          [ 0.0000e+00, -2.1475e+09,  2.9384e-39,  ...,  9.4447e+21,\n",
              "            1.9102e-38,  0.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0000e+00,  0.0000e+00, -4.2136e+37,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.7389e-32,\n",
              "            8.5479e-44,  0.0000e+00],\n",
              "          ...,\n",
              "          [ 0.0000e+00, -1.6945e+38, -1.6947e+38,  ...,  1.3369e+08,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.4388e-41,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  9.6296e-35,  ..., -2.5860e+33,\n",
              "            3.8295e-41,  0.0000e+00]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq4urZEPB5uQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_ = d(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovv4cIEuJV7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "190f4a5f-6d3c-441a-be0e-4738fa9c9e83"
      },
      "source": [
        "y_\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4985, 0.4980, 0.4947,  ..., 0.5012, 0.5003, 0.5027],\n",
              "       grad_fn=<ViewBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTC2AiFEJYnw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "04881aa2-5749-4d35-a521-15ab3935007d"
      },
      "source": [
        "y"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPqEo7lxJecs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "143f70fe-8949-4c9c-c6d0-1c2e541e29b3"
      },
      "source": [
        "y_.size()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([115200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqFP6yV_JgKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "afe4febf-3296-4e82-acd4-f9260a878ff9"
      },
      "source": [
        "y.size()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FviLR9c8M4M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}